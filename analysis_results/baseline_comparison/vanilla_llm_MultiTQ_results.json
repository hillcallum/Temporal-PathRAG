{
  "dataset": "MultiTQ",
  "split": "test",
  "timestamp": "2025-07-11T12:31:30.142815",
  "overall_metrics": {
    "exact_match": 1.832038692657189e-05,
    "f1_score": 3.2480099899123784e-05,
    "temporal_accuracy": 1.832038692657189e-05,
    "entity_accuracy": 2.5839793281653746e-05,
    "mrr": 1.832038692657189e-05,
    "hits_at_1": 1.832038692657189e-05,
    "hits_at_3": 3.2480099899123784e-05,
    "hits_at_10": 3.897611987894854e-05,
    "total_questions": 54584,
    "correct_predictions": 1.0
  },
  "efficiency_metrics": {
    "avg_retrieval_time": 0.0,
    "avg_reasoning_time": 0.35321473598480224
  },
  "breakdown": {
    "by_type": {
      "after_first": {
        "exact_match": 0.0,
        "f1_score": 0.0,
        "count": 8
      },
      "first_last": {
        "exact_match": 0.0,
        "f1_score": 0.0,
        "count": 26
      },
      "before_last": {
        "exact_match": 0.08333333333333333,
        "f1_score": 0.08333333333333333,
        "count": 12
      },
      "before_after": {
        "exact_match": 0.0,
        "f1_score": 0.030952380952380953,
        "count": 20
      },
      "equal_multi": {
        "exact_match": 0.0,
        "f1_score": 0.0,
        "count": 3
      },
      "equal": {
        "exact_match": 0.0,
        "f1_score": 0.004962779156327543,
        "count": 31
      }
    },
    "by_granularity": {
      "day": {
        "accuracy": 0.017543859649122806,
        "count": 57
      },
      "year": {
        "accuracy": 0.0,
        "count": 21
      },
      "month": {
        "accuracy": 0.0,
        "count": 22
      }
    }
  },
  "error_analysis": {
    "entity_error": 59,
    "temporal_error": 40,
    "missing_prediction": 54484
  }
}